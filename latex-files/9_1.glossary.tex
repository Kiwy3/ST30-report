%\makeglossaries
%general
\newacronym{sota}{SOTA}{State-of-the-art}
\newacronym{flops}{FLOPS}{Floating-Point Operations per Second}
%chap 2.1
\newacronym{llm}{LLM}{Large Language Models}
\newacronym{dnn}{DNN}{Deep Neural Networks}
\newacronym{mha}{MHA}{Multi-Head Attention}
\newacronym{ann}{ANN}{Artificial Neural Networks}
\newacronym{nn}{NN}{Neural Networks}
\newacronym{nlp}{NLP}{Natural Language Processing}
\newacronym{gpt}{GPT}{Generative Pre-Trained}
\newacronym{sgd}{SGD}{Stochastic Gradient Descent}
\newacronym{adam}{Adam}{Adaptive Moment Estimation}
\newacronym{lstm}{LTSM}{Long Short-Term Memory}
\newacronym{peft}{PEFT}{Parameter Efficient Fine-Tuning}
\newacronym{lora}{LoRA}{Low Rank Adaptation}
\newacronym{mse}{MSE}{Mean-Squared Error}
\newacronym{mlp}{MLP}{Multi-Layer Perceptron}
\newacronym{cnn}{CNN}{Convolutional Neural Networks}
\newacronym{vae}{VAE}{Variable Auto-Encoder}


%chap 2.2
\newacronym{bo}{BO}{Bayesian Optimization}
\newacronym{nas}{NAS}{Neural Architecture Search}
\newacronym{hpo}{HPO}{Hyper-Parameter Optimization}
\newacronym{automl}{Auto-ML}{Automated Machine Learning}
\newacronym{autodnn}{Auto-DNN}{Automated Deep Neural Networks}
\newacronym{mvop}{MVOP}{Mixed Variable-size Optimization Problem}
\newacronym{ml}{ML}{Machine Learning}
\newacronym{gs}{GS}{Grid Search}
\newacronym{rs}{RS}{Random Search}
\newacronym{ea}{EA}{Evolutionnary Algorithms}
\newacronym{ga}{GA}{Genetic Algorithms}
\newacronym{ils}{ILS}{Iterated Local Search}
\newacronym{sa}{SA}{Simulated Annealing}
\newacronym{pbo}{PBO}{Partition Based Optimization}
\newacronym{smbo}{SMBO}{Surrogate-Model Based Optimization}
\newacronym{soo}{SOO}{Simultaneous Optimistic Optimization}
\newacronym{fda}{FDA}{Fractal Decomposition Algorithm}
\newacronym{direct}{DIRECT}{DIviding RECTangle}
\newacronym{gp}{GP}{Gaussian Process}
\newacronym{gpu}{GPU}{Graphics Processing Unit}
\newacronym{hpc}{HPC}{High Performance Computing}
\newacronym{poc}{POC}{Proof-of-Concept}

\newacronym{qc}{QC}{Quality Control}
\newacronym{scm}{SCM}{Supply Chain Management}

% Chap 3
\newacronym{adamw}{AdamW}{Adaptive Moment Estimation with Weight Decay}
\newacronym{cli}{CLI}{Command Line Interface}
\newacronym{mcq}{MCQ}{Multi-Choice Question}
\newacronym{lhs}{LHS}{Latin Hypercube Sampling}
\newacronym{bamsoo}{BaMSOO}{Bayesian Multi Scale Optimistic Optimization}
\newacronym{mcts}{MCTS}{Monte Carlo Tree Search}
\newacronym{ucb}{$\mathcal {UCB}$}{Upper Confidence Bound}
\newacronym{lcb}{LCB}{Lower Confidence Bound}


% Glossary
\newglossaryentry{transformer}
{
    name=transformer,
    plural=transformers,
    description={Neural networks layers type using attention mechanisms}
}
\newglossaryentry{fine_tuning}
{
    name=fine-tuning,
    description={2nd step of \acrshort{llm} training}
}
\newglossaryentry{pre-training}
{
    name=pre-training,
    description={1st step of training \acrshort{llm}}
}

\newglossaryentry{instruction-tuning}
{
    name=instruction tuning,
    description={Fine-tuning with Instruction and behavior dataset}
}
\newglossaryentry{hyperparameter}
{
    name=hyperparameter,
    plural=hyperparameters,
    description={Parameters not learned by the model}
}
\newglossaryentry{search_space}
{
    name=search space,
    plural=search spaces,
    description={need to define it}
}

\newglossaryentry{search_strat}
{
    name=search strategy ,
    plural=search strategies,
    description={need to define it}
}
\newglossaryentry{perf_est}
{
    name=performances estimation strategy ,
    plural=performances estimation strategies,
    description={need to define it}
}
\newglossaryentry{pytorch}{
    name = PyTorch,
    description = {Tensor-based framework for machine learning}
}
\newglossaryentry{lightning}{
    name = PyTorch Lightning,
    description = {automated deep learning training framework}
}
\newglossaryentry{litgpt}{
    name = litgpt,
    description = {PyTorch based framework for training \acrshort{llm}}
}
\newglossaryentry{hf}{
    name = HuggingFace,
    description = {Deep Learning Hub with models and datasets}
}